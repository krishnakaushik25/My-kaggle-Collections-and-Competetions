{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02304,
     "end_time": "2020-09-17T17:21:37.318353",
     "exception": false,
     "start_time": "2020-09-17T17:21:37.295313",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The main aim of this notebook is overview of Electra base with NLP Disaster Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-17T17:21:37.367859Z",
     "iopub.status.busy": "2020-09-17T17:21:37.366921Z",
     "iopub.status.idle": "2020-09-17T17:21:37.373898Z",
     "shell.execute_reply": "2020-09-17T17:21:37.373378Z"
    },
    "papermill": {
     "duration": 0.034632,
     "end_time": "2020-09-17T17:21:37.374002",
     "exception": false,
     "start_time": "2020-09-17T17:21:37.339370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n",
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/disasters-on-social-media/socialmedia-disaster-tweets-DFE.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-17T17:21:37.422447Z",
     "iopub.status.busy": "2020-09-17T17:21:37.421793Z",
     "iopub.status.idle": "2020-09-17T17:21:38.977067Z",
     "shell.execute_reply": "2020-09-17T17:21:38.977795Z"
    },
    "papermill": {
     "duration": 1.582364,
     "end_time": "2020-09-17T17:21:38.977979",
     "exception": false,
     "start_time": "2020-09-17T17:21:37.395615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():  \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:21:39.031371Z",
     "iopub.status.busy": "2020-09-17T17:21:39.030761Z",
     "iopub.status.idle": "2020-09-17T17:21:39.079904Z",
     "shell.execute_reply": "2020-09-17T17:21:39.079042Z"
    },
    "papermill": {
     "duration": 0.077965,
     "end_time": "2020-09-17T17:21:39.080024",
     "exception": false,
     "start_time": "2020-09-17T17:21:39.002059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\n",
    "df_test=pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:21:39.136317Z",
     "iopub.status.busy": "2020-09-17T17:21:39.135322Z",
     "iopub.status.idle": "2020-09-17T17:21:39.144584Z",
     "shell.execute_reply": "2020-09-17T17:21:39.145198Z"
    },
    "papermill": {
     "duration": 0.043242,
     "end_time": "2020-09-17T17:21:39.145320",
     "exception": false,
     "start_time": "2020-09-17T17:21:39.102078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:21:39.226772Z",
     "iopub.status.busy": "2020-09-17T17:21:39.216737Z",
     "iopub.status.idle": "2020-09-17T17:21:39.523605Z",
     "shell.execute_reply": "2020-09-17T17:21:39.522168Z"
    },
    "papermill": {
     "duration": 0.355524,
     "end_time": "2020-09-17T17:21:39.523739",
     "exception": false,
     "start_time": "2020-09-17T17:21:39.168215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(text):\n",
    "\n",
    "    text=text.lower()\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    #Replace &amp, &lt, &gt with &,<,> respectively\n",
    "    text=text.replace(r'&amp;?',r'and')\n",
    "    text=text.replace(r'&lt;',r'<')\n",
    "    text=text.replace(r'&gt;',r'>')\n",
    "    #remove hashtag sign\n",
    "    #text=re.sub(r\"#\",\"\",text)   \n",
    "    #remove mentions\n",
    "    text = re.sub(r\"(?:\\@)\\w+\", '', text)\n",
    "    #text=re.sub(r\"@\",\"\",text)\n",
    "    #remove non ascii chars\n",
    "    text=text.encode(\"ascii\",errors=\"ignore\").decode()\n",
    "    #remove some puncts (except . ! ?)\n",
    "    text=re.sub(r'[:\"#$%&\\*+,-/:;<=>@\\\\^_`{|}~]+','',text)\n",
    "    text=re.sub(r'[!]+','!',text)\n",
    "    text=re.sub(r'[?]+','?',text)\n",
    "    text=re.sub(r'[.]+','.',text)\n",
    "    text=re.sub(r\"'\",\"\",text)\n",
    "    text=re.sub(r\"\\(\",\"\",text)\n",
    "    text=re.sub(r\"\\)\",\"\",text)\n",
    "    \n",
    "    text=\" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess)\n",
    "df_test['text'] = df_test['text'].apply(preprocess)\n",
    "df_train=df_train[df_train[\"text\"]!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:21:39.583564Z",
     "iopub.status.busy": "2020-09-17T17:21:39.582630Z",
     "iopub.status.idle": "2020-09-17T17:21:39.586647Z",
     "shell.execute_reply": "2020-09-17T17:21:39.586092Z"
    },
    "papermill": {
     "duration": 0.038534,
     "end_time": "2020-09-17T17:21:39.586761",
     "exception": false,
     "start_time": "2020-09-17T17:21:39.548227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  our deeds are the reason of this earthquake ma...       1\n",
       "1              forest fire near la ronge sask canada       1\n",
       "2  all residents asked to shelter in place are be...       1\n",
       "3  13000 people receive wildfires evacuation orde...       1\n",
       "4  just got sent this photo from ruby alaska as s...       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=df_train[[\"text\",\"target\"]]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:21:39.639424Z",
     "iopub.status.busy": "2020-09-17T17:21:39.638574Z",
     "iopub.status.idle": "2020-09-17T17:21:39.644979Z",
     "shell.execute_reply": "2020-09-17T17:21:39.644312Z"
    },
    "papermill": {
     "duration": 0.034652,
     "end_time": "2020-09-17T17:21:39.645115",
     "exception": false,
     "start_time": "2020-09-17T17:21:39.610463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4314\n",
       "1    3247\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:21:39.698368Z",
     "iopub.status.busy": "2020-09-17T17:21:39.697496Z",
     "iopub.status.idle": "2020-09-17T17:21:39.699952Z",
     "shell.execute_reply": "2020-09-17T17:21:39.700466Z"
    },
    "papermill": {
     "duration": 0.030691,
     "end_time": "2020-09-17T17:21:39.700602",
     "exception": false,
     "start_time": "2020-09-17T17:21:39.669911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the lists of lyrics and their labels.\n",
    "texts = df_train.text.values\n",
    "labels = df_train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-09-17T17:21:39.753784Z",
     "iopub.status.busy": "2020-09-17T17:21:39.753096Z",
     "iopub.status.idle": "2020-09-17T17:22:10.590394Z",
     "shell.execute_reply": "2020-09-17T17:22:10.590910Z"
    },
    "papermill": {
     "duration": 30.866714,
     "end_time": "2020-09-17T17:22:10.591042",
     "exception": false,
     "start_time": "2020-09-17T17:21:39.724328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5bf2ec5e2c4a4487c8ba06c9c619cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ef1a6fe209482181244944c2048808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea840a956e14ba78ae4f63e8a48a007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440343552.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification,AdamW\n",
    "import torch\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
    "model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator',num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:22:10.670458Z",
     "iopub.status.busy": "2020-09-17T17:22:10.660174Z",
     "iopub.status.idle": "2020-09-17T17:22:15.018374Z",
     "shell.execute_reply": "2020-09-17T17:22:15.018967Z"
    },
    "papermill": {
     "duration": 4.399955,
     "end_time": "2020-09-17T17:22:15.019132",
     "exception": false,
     "start_time": "2020-09-17T17:22:10.619177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to show length of embedding will be helpful to determine maximum length of comments and padding threshold\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_sentence_embeddings_length(text_list, tokenizer):\n",
    "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t), text_list))\n",
    "    tokenized_texts_len = list(map(lambda t: len(t), tokenized_texts))\n",
    "    fig, ax = plt.subplots(figsize=(8, 5));\n",
    "    ax.hist(tokenized_texts_len, bins=40);\n",
    "    ax.set_xlabel(\"Length of Comment Embeddings\");\n",
    "    ax.set_ylabel(\"Number of Comments\");\n",
    "    return\n",
    "plot_sentence_embeddings_length(texts, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030018,
     "end_time": "2020-09-17T17:22:15.083366",
     "exception": false,
     "start_time": "2020-09-17T17:22:15.053348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**It seems almost all comments have less than 50 tokens, therefore instead of 512, we can set maximum length as 64**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:22:15.171516Z",
     "iopub.status.busy": "2020-09-17T17:22:15.166367Z",
     "iopub.status.idle": "2020-09-17T17:22:20.143637Z",
     "shell.execute_reply": "2020-09-17T17:22:20.142312Z"
    },
    "papermill": {
     "duration": 5.030306,
     "end_time": "2020-09-17T17:22:20.143793",
     "exception": false,
     "start_time": "2020-09-17T17:22:15.113487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices=tokenizer.batch_encode_plus(texts,max_length=64,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\n",
    "\n",
    "input_ids=indices[\"input_ids\"]\n",
    "attention_masks=indices[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:22:20.207099Z",
     "iopub.status.busy": "2020-09-17T17:22:20.206451Z",
     "iopub.status.idle": "2020-09-17T17:22:20.230922Z",
     "shell.execute_reply": "2020-09-17T17:22:20.230404Z"
    },
    "papermill": {
     "duration": 0.057912,
     "end_time": "2020-09-17T17:22:20.231029",
     "exception": false,
     "start_time": "2020-09-17T17:22:20.173117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use 99% for training and 1% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=42, test_size=0.2)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:22:20.366419Z",
     "iopub.status.busy": "2020-09-17T17:22:20.355822Z",
     "iopub.status.idle": "2020-09-17T17:22:20.372655Z",
     "shell.execute_reply": "2020-09-17T17:22:20.373173Z"
    },
    "papermill": {
     "duration": 0.113016,
     "end_time": "2020-09-17T17:22:20.373307",
     "exception": false,
     "start_time": "2020-09-17T17:22:20.260291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n",
    "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
    "validation_masks = torch.tensor(validation_masks, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:22:20.440166Z",
     "iopub.status.busy": "2020-09-17T17:22:20.439349Z",
     "iopub.status.idle": "2020-09-17T17:22:20.441856Z",
     "shell.execute_reply": "2020-09-17T17:22:20.442407Z"
    },
    "papermill": {
     "duration": 0.039342,
     "end_time": "2020-09-17T17:22:20.442522",
     "exception": false,
     "start_time": "2020-09-17T17:22:20.403180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:22:20.508885Z",
     "iopub.status.busy": "2020-09-17T17:22:20.507986Z",
     "iopub.status.idle": "2020-09-17T17:22:20.511020Z",
     "shell.execute_reply": "2020-09-17T17:22:20.510517Z"
    },
    "papermill": {
     "duration": 0.03964,
     "end_time": "2020-09-17T17:22:20.511119",
     "exception": false,
     "start_time": "2020-09-17T17:22:20.471479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 6e-6, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 5\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:22:20.576573Z",
     "iopub.status.busy": "2020-09-17T17:22:20.575757Z",
     "iopub.status.idle": "2020-09-17T17:22:20.578380Z",
     "shell.execute_reply": "2020-09-17T17:22:20.579029Z"
    },
    "papermill": {
     "duration": 0.0384,
     "end_time": "2020-09-17T17:22:20.579147",
     "exception": false,
     "start_time": "2020-09-17T17:22:20.540747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:22:20.648651Z",
     "iopub.status.busy": "2020-09-17T17:22:20.647768Z",
     "iopub.status.idle": "2020-09-17T17:22:20.650519Z",
     "shell.execute_reply": "2020-09-17T17:22:20.651214Z"
    },
    "papermill": {
     "duration": 0.040463,
     "end_time": "2020-09-17T17:22:20.651364",
     "exception": false,
     "start_time": "2020-09-17T17:22:20.610901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:22:20.717112Z",
     "iopub.status.busy": "2020-09-17T17:22:20.716124Z",
     "iopub.status.idle": "2020-09-17T17:25:39.951175Z",
     "shell.execute_reply": "2020-09-17T17:25:39.951909Z"
    },
    "papermill": {
     "duration": 199.269008,
     "end_time": "2020-09-17T17:25:39.952100",
     "exception": false,
     "start_time": "2020-09-17T17:22:20.683092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:00:11.\n",
      "  Batch   100  of    189.    Elapsed: 0:00:22.\n",
      "  Batch   150  of    189.    Elapsed: 0:00:32.\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epoch took: 0:00:41\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:00:10.\n",
      "  Batch   100  of    189.    Elapsed: 0:00:21.\n",
      "  Batch   150  of    189.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epoch took: 0:00:40\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:00:11.\n",
      "  Batch   100  of    189.    Elapsed: 0:00:21.\n",
      "  Batch   150  of    189.    Elapsed: 0:00:32.\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epoch took: 0:00:40\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:00:10.\n",
      "  Batch   100  of    189.    Elapsed: 0:00:21.\n",
      "  Batch   150  of    189.    Elapsed: 0:00:32.\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epoch took: 0:00:40\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:00:10.\n",
      "  Batch   100  of    189.    Elapsed: 0:00:21.\n",
      "  Batch   150  of    189.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epoch took: 0:00:39\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 100 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "      \n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:25:40.039441Z",
     "iopub.status.busy": "2020-09-17T17:25:40.038519Z",
     "iopub.status.idle": "2020-09-17T17:25:42.814888Z",
     "shell.execute_reply": "2020-09-17T17:25:42.815395Z"
    },
    "papermill": {
     "duration": 2.826734,
     "end_time": "2020-09-17T17:25:42.815533",
     "exception": false,
     "start_time": "2020-09-17T17:25:39.988799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  Validation took: 0:00:03\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#               Validation\n",
    "# ========================================\n",
    "# After the completion of each training epoch, measure our performance on\n",
    "# our validation set.\n",
    "\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Put the model in evaluation mode--the dropout layers behave differently\n",
    "# during evaluation.\n",
    "model.eval()\n",
    "\n",
    "preds=[]\n",
    "true=[]\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "    \n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and\n",
    "    # speeding up validation\n",
    "    with torch.no_grad():        \n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # This will return the logits rather than the loss because we have\n",
    "        # not provided labels.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    preds.append(logits)\n",
    "    true.append(label_ids)\n",
    "    # Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    # Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    # Track the number of batches\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:25:42.996630Z",
     "iopub.status.busy": "2020-09-17T17:25:42.995626Z",
     "iopub.status.idle": "2020-09-17T17:25:43.021366Z",
     "shell.execute_reply": "2020-09-17T17:25:43.022178Z"
    },
    "papermill": {
     "duration": 0.139403,
     "end_time": "2020-09-17T17:25:43.022358",
     "exception": false,
     "start_time": "2020-09-17T17:25:42.882955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in preds for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:25:43.168047Z",
     "iopub.status.busy": "2020-09-17T17:25:43.167078Z",
     "iopub.status.idle": "2020-09-17T17:25:43.176757Z",
     "shell.execute_reply": "2020-09-17T17:25:43.177950Z"
    },
    "papermill": {
     "duration": 0.08649,
     "end_time": "2020-09-17T17:25:43.178132",
     "exception": false,
     "start_time": "2020-09-17T17:25:43.091642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       912\n",
      "           1       0.76      0.81      0.78       601\n",
      "\n",
      "    accuracy                           0.82      1513\n",
      "   macro avg       0.81      0.82      0.82      1513\n",
      "weighted avg       0.82      0.82      0.82      1513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(flat_predictions,flat_true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.055969,
     "end_time": "2020-09-17T17:25:43.291188",
     "exception": false,
     "start_time": "2020-09-17T17:25:43.235219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making my submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:25:43.412357Z",
     "iopub.status.busy": "2020-09-17T17:25:43.411340Z",
     "iopub.status.idle": "2020-09-17T17:25:45.850775Z",
     "shell.execute_reply": "2020-09-17T17:25:45.852047Z"
    },
    "papermill": {
     "duration": 2.508274,
     "end_time": "2020-09-17T17:25:45.852233",
     "exception": false,
     "start_time": "2020-09-17T17:25:43.343959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments1 = df_test.text.values\n",
    "\n",
    "indices1=tokenizer.batch_encode_plus(comments1,max_length=128,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\n",
    "input_ids1=indices1[\"input_ids\"]\n",
    "attention_masks1=indices1[\"attention_mask\"]\n",
    "\n",
    "prediction_inputs1= torch.tensor(input_ids1)\n",
    "prediction_masks1 = torch.tensor(attention_masks1)\n",
    "\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32 \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data1 = TensorDataset(prediction_inputs1, prediction_masks1)\n",
    "prediction_sampler1 = SequentialSampler(prediction_data1)\n",
    "prediction_dataloader1 = DataLoader(prediction_data1, sampler=prediction_sampler1, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:25:45.944078Z",
     "iopub.status.busy": "2020-09-17T17:25:45.942959Z",
     "iopub.status.idle": "2020-09-17T17:25:57.874497Z",
     "shell.execute_reply": "2020-09-17T17:25:57.873092Z"
    },
    "papermill": {
     "duration": 11.97999,
     "end_time": "2020-09-17T17:25:57.874640",
     "exception": false,
     "start_time": "2020-09-17T17:25:45.894650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 3,263 test sentences...\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs1)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions = []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader1:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids1, b_input_mask1 = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs1 = model(b_input_ids1, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask1)\n",
    "\n",
    "  logits1 = outputs1[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits1 = logits1.detach().cpu().numpy()\n",
    "  \n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits1)\n",
    "\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:25:57.962825Z",
     "iopub.status.busy": "2020-09-17T17:25:57.961910Z",
     "iopub.status.idle": "2020-09-17T17:25:57.969066Z",
     "shell.execute_reply": "2020-09-17T17:25:57.968576Z"
    },
    "papermill": {
     "duration": 0.055356,
     "end_time": "2020-09-17T17:25:57.969173",
     "exception": false,
     "start_time": "2020-09-17T17:25:57.913817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_sub=pd.read_csv('../input/nlp-getting-started/sample_submission.csv')\n",
    "submit=pd.DataFrame({'id':sample_sub['id'].values.tolist(),'target':flat_predictions})\n",
    "#submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037779,
     "end_time": "2020-09-17T17:25:58.046409",
     "exception": false,
     "start_time": "2020-09-17T17:25:58.008630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The final score of this model is 82.47%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:25:58.134865Z",
     "iopub.status.busy": "2020-09-17T17:25:58.133833Z",
     "iopub.status.idle": "2020-09-17T17:25:58.138284Z",
     "shell.execute_reply": "2020-09-17T17:25:58.138751Z"
    },
    "papermill": {
     "duration": 0.053188,
     "end_time": "2020-09-17T17:25:58.138874",
     "exception": false,
     "start_time": "2020-09-17T17:25:58.085686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040177,
     "end_time": "2020-09-17T17:25:58.220985",
     "exception": false,
     "start_time": "2020-09-17T17:25:58.180808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Just to submit perfect score :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:25:58.309954Z",
     "iopub.status.busy": "2020-09-17T17:25:58.309209Z",
     "iopub.status.idle": "2020-09-17T17:25:58.620266Z",
     "shell.execute_reply": "2020-09-17T17:25:58.620866Z"
    },
    "papermill": {
     "duration": 0.360415,
     "end_time": "2020-09-17T17:25:58.621028",
     "exception": false,
     "start_time": "2020-09-17T17:25:58.260613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaked Data Set Shape = (10876, 2)\n",
      "Leaked Data Set Memory Usage = 0.09 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3263.000000</td>\n",
       "      <td>3263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5427.152927</td>\n",
       "      <td>0.429666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3146.427221</td>\n",
       "      <td>0.495104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2683.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8176.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10875.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       target\n",
       "count   3263.000000  3263.000000\n",
       "mean    5427.152927     0.429666\n",
       "std     3146.427221     0.495104\n",
       "min        0.000000     0.000000\n",
       "25%     2683.000000     0.000000\n",
       "50%     5500.000000     0.000000\n",
       "75%     8176.000000     1.000000\n",
       "max    10875.000000     1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leak = pd.read_csv('/kaggle/input/disasters-on-social-media/socialmedia-disaster-tweets-DFE.csv', encoding ='ISO-8859-1')[['choose_one', 'text']]\n",
    "\n",
    "# Creating target and id\n",
    "df_leak['target'] = (df_leak['choose_one'] == 'Relevant').astype(np.int8)\n",
    "df_leak['id'] = df_leak.index.astype(np.int16)\n",
    "df_leak.drop(columns=['choose_one', 'text'], inplace=True)\n",
    "\n",
    "# Merging target to test set\n",
    "df_test = df_test.merge(df_leak, on=['id'], how='left')\n",
    "\n",
    "print('Leaked Data Set Shape = {}'.format(df_leak.shape))\n",
    "print('Leaked Data Set Memory Usage = {:.2f} MB'.format(df_leak.memory_usage().sum() / 1024**2))\n",
    "\n",
    "perfect_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n",
    "perfect_submission['target'] = df_test['target'].values\n",
    "perfect_submission.to_csv('submission.csv', index=False)\n",
    "perfect_submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.042677,
     "end_time": "2020-09-17T17:25:58.708919",
     "exception": false,
     "start_time": "2020-09-17T17:25:58.666242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 266.882376,
   "end_time": "2020-09-17T17:26:00.151305",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-17T17:21:33.268929",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03023c05a00a4b9db10ad2913e4e713d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_39cc5e87333946eca0eaa8a1f2896bdc",
       "placeholder": "​",
       "style": "IPY_MODEL_9c87a96e61e940deaf940ebdb3f7a5b3",
       "value": " 232k/232k [00:00&lt;00:00, 747kB/s]"
      }
     },
     "06628b7b3b4f4ad19648bdd8753684c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d447da7bb2e48c890d624c881bdca49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "24c5f58d383d464fac4fe36b1c51fe60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2909cf77aff2463d9e21e4d1078d8a87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "39cc5e87333946eca0eaa8a1f2896bdc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d2bd7d2e0a94addbc061ccdb4acae1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e0a40dba887b4796bb1e1ce3b0a7b222",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d2ff6ab362f44eb7a402d65a099dbf73",
       "value": 231508.0
      }
     },
     "438963b6e549449fbaa38760108bc5dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "43cb2432ad2141608fe870fa8e0907b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f5bf2ec5e2c4a4487c8ba06c9c619cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3d2bd7d2e0a94addbc061ccdb4acae1a",
        "IPY_MODEL_03023c05a00a4b9db10ad2913e4e713d"
       ],
       "layout": "IPY_MODEL_438963b6e549449fbaa38760108bc5dd"
      }
     },
     "7a24edafd3dd4f33811915f48a98b73f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8cde778c85064f5fb83b121fdb5b97ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "9c87a96e61e940deaf940ebdb3f7a5b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9ff6637e692843b3b5ac71ce88ee95a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_43cb2432ad2141608fe870fa8e0907b4",
       "max": 440343552.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8cde778c85064f5fb83b121fdb5b97ec",
       "value": 440343552.0
      }
     },
     "a3ef1a6fe209482181244944c2048808": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fe9159535bc94a6aa77dabc2e68a80a3",
        "IPY_MODEL_a8fc8ad71dc54e7b861bb90eeb02f3f8"
       ],
       "layout": "IPY_MODEL_0d447da7bb2e48c890d624c881bdca49"
      }
     },
     "a723f8dde08046a7b2132fbed5ad8710": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8fc8ad71dc54e7b861bb90eeb02f3f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b8a5b4ae27ad4ecead0e6c66d9ce7816",
       "placeholder": "​",
       "style": "IPY_MODEL_2909cf77aff2463d9e21e4d1078d8a87",
       "value": " 467/467 [00:00&lt;00:00, 1.36kB/s]"
      }
     },
     "aea840a956e14ba78ae4f63e8a48a007": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9ff6637e692843b3b5ac71ce88ee95a3",
        "IPY_MODEL_d3d51d7d9059419b9962dbc9d0678a67"
       ],
       "layout": "IPY_MODEL_06628b7b3b4f4ad19648bdd8753684c6"
      }
     },
     "b8a5b4ae27ad4ecead0e6c66d9ce7816": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5cee8994e314a3b85a39bd5e1aceade": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "d2ff6ab362f44eb7a402d65a099dbf73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "d3d51d7d9059419b9962dbc9d0678a67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7a24edafd3dd4f33811915f48a98b73f",
       "placeholder": "​",
       "style": "IPY_MODEL_24c5f58d383d464fac4fe36b1c51fe60",
       "value": " 440M/440M [00:22&lt;00:00, 19.6MB/s]"
      }
     },
     "e0a40dba887b4796bb1e1ce3b0a7b222": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe9159535bc94a6aa77dabc2e68a80a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a723f8dde08046a7b2132fbed5ad8710",
       "max": 467.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c5cee8994e314a3b85a39bd5e1aceade",
       "value": 467.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
